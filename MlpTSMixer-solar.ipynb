{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bba619e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f19b0e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kashif/.env/pytorch/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/kashif/.env/pytorch/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c106detail23torchInternalAssertFailEPKcS2_jS2_RKSs'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from gluonts.dataset.multivariate_grouper import MultivariateGrouper\n",
    "from gluonts.dataset.repository.datasets import dataset_recipes, get_dataset\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "from gluonts.evaluation import MultivariateEvaluator\n",
    "\n",
    "from MlpTSMixer import MlpTSMixerEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5f6bba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_dataset(\"solar_nips\", regenerate=False)\n",
    "train_grouper = MultivariateGrouper(\n",
    "    max_target_dim=int(dataset.metadata.feat_static_cat[0].cardinality)\n",
    ")\n",
    "\n",
    "test_grouper = MultivariateGrouper(\n",
    "    num_test_dates=int(len(dataset.test) / len(dataset.train)),\n",
    "    max_target_dim=int(dataset.metadata.feat_static_cat[0].cardinality),\n",
    ")\n",
    "dataset_train = train_grouper(dataset.train)\n",
    "dataset_test = test_grouper(dataset.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98a007c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = MlpTSMixerEstimator(\n",
    "    # distr_output=StudentTOutput(dim=int(dataset.metadata.feat_static_cat[0].cardinality)),\n",
    "    input_size=int(dataset.metadata.feat_static_cat[0].cardinality),\n",
    "    prediction_length=dataset.metadata.prediction_length,\n",
    "    context_length=dataset.metadata.prediction_length * 3,\n",
    "    freq=dataset.metadata.freq,\n",
    "    scaling=\"std\",\n",
    "    pooling_type=\"max\",\n",
    "    depth=2,\n",
    "    patch_size=(5, 5),\n",
    "    dim=32,\n",
    "    expansion_factor=1,\n",
    "    batch_size=64,\n",
    "    num_batches_per_epoch=100,\n",
    "    trainer_kwargs=dict(accelerator=\"cuda\", max_epochs=100),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c30625db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Authorization required, but no authorization protocol specified\n",
      "Authorization required, but no authorization protocol specified\n",
      "Authorization required, but no authorization protocol specified\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/kashif/.env/pytorch/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:72: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type            | Params\n",
      "------------------------------------------\n",
      "0 | model | MlpTSMixerModel | 582 K \n",
      "------------------------------------------\n",
      "582 K     Trainable params\n",
      "0         Non-trainable params\n",
      "582 K     Total params\n",
      "2.328     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed94d6c960694aa6b3ab371ae1c8ee9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 100: 'train_loss' reached 4.29688 (best 4.29688), saving model to '/mnt/scratch/kashif/ConvTS-Mixer/lightning_logs/version_142/checkpoints/epoch=0-step=100.ckpt' as top 1\n",
      "Epoch 1, global step 200: 'train_loss' reached 3.79278 (best 3.79278), saving model to '/mnt/scratch/kashif/ConvTS-Mixer/lightning_logs/version_142/checkpoints/epoch=1-step=200.ckpt' as top 1\n",
      "Epoch 2, global step 300: 'train_loss' reached 3.68673 (best 3.68673), saving model to '/mnt/scratch/kashif/ConvTS-Mixer/lightning_logs/version_142/checkpoints/epoch=2-step=300.ckpt' as top 1\n",
      "Epoch 3, global step 400: 'train_loss' reached 3.62648 (best 3.62648), saving model to '/mnt/scratch/kashif/ConvTS-Mixer/lightning_logs/version_142/checkpoints/epoch=3-step=400.ckpt' as top 1\n",
      "Epoch 4, global step 500: 'train_loss' was not in top 1\n",
      "Epoch 5, global step 600: 'train_loss' reached 3.60439 (best 3.60439), saving model to '/mnt/scratch/kashif/ConvTS-Mixer/lightning_logs/version_142/checkpoints/epoch=5-step=600.ckpt' as top 1\n",
      "Epoch 6, global step 700: 'train_loss' reached 3.57114 (best 3.57114), saving model to '/mnt/scratch/kashif/ConvTS-Mixer/lightning_logs/version_142/checkpoints/epoch=6-step=700.ckpt' as top 1\n",
      "Epoch 7, global step 800: 'train_loss' reached 3.56071 (best 3.56071), saving model to '/mnt/scratch/kashif/ConvTS-Mixer/lightning_logs/version_142/checkpoints/epoch=7-step=800.ckpt' as top 1\n",
      "Epoch 8, global step 900: 'train_loss' reached 3.54236 (best 3.54236), saving model to '/mnt/scratch/kashif/ConvTS-Mixer/lightning_logs/version_142/checkpoints/epoch=8-step=900.ckpt' as top 1\n",
      "Epoch 9, global step 1000: 'train_loss' reached 3.53300 (best 3.53300), saving model to '/mnt/scratch/kashif/ConvTS-Mixer/lightning_logs/version_142/checkpoints/epoch=9-step=1000.ckpt' as top 1\n",
      "Epoch 10, global step 1100: 'train_loss' reached 3.52396 (best 3.52396), saving model to '/mnt/scratch/kashif/ConvTS-Mixer/lightning_logs/version_142/checkpoints/epoch=10-step=1100.ckpt' as top 1\n",
      "Epoch 11, global step 1200: 'train_loss' reached 3.50378 (best 3.50378), saving model to '/mnt/scratch/kashif/ConvTS-Mixer/lightning_logs/version_142/checkpoints/epoch=11-step=1200.ckpt' as top 1\n",
      "Epoch 12, global step 1300: 'train_loss' reached 3.48698 (best 3.48698), saving model to '/mnt/scratch/kashif/ConvTS-Mixer/lightning_logs/version_142/checkpoints/epoch=12-step=1300.ckpt' as top 1\n",
      "Epoch 13, global step 1400: 'train_loss' reached 3.46177 (best 3.46177), saving model to '/mnt/scratch/kashif/ConvTS-Mixer/lightning_logs/version_142/checkpoints/epoch=13-step=1400.ckpt' as top 1\n",
      "Epoch 14, global step 1500: 'train_loss' was not in top 1\n",
      "Epoch 15, global step 1600: 'train_loss' reached 3.45297 (best 3.45297), saving model to '/mnt/scratch/kashif/ConvTS-Mixer/lightning_logs/version_142/checkpoints/epoch=15-step=1600.ckpt' as top 1\n",
      "Epoch 16, global step 1700: 'train_loss' reached 3.44296 (best 3.44296), saving model to '/mnt/scratch/kashif/ConvTS-Mixer/lightning_logs/version_142/checkpoints/epoch=16-step=1700.ckpt' as top 1\n",
      "Epoch 17, global step 1800: 'train_loss' reached 3.43653 (best 3.43653), saving model to '/mnt/scratch/kashif/ConvTS-Mixer/lightning_logs/version_142/checkpoints/epoch=17-step=1800.ckpt' as top 1\n",
      "Epoch 18, global step 1900: 'train_loss' was not in top 1\n",
      "Epoch 19, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 20, global step 2100: 'train_loss' reached 3.40685 (best 3.40685), saving model to '/mnt/scratch/kashif/ConvTS-Mixer/lightning_logs/version_142/checkpoints/epoch=20-step=2100.ckpt' as top 1\n",
      "Epoch 21, global step 2200: 'train_loss' was not in top 1\n",
      "Epoch 22, global step 2300: 'train_loss' was not in top 1\n",
      "Epoch 23, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 24, global step 2500: 'train_loss' was not in top 1\n",
      "Epoch 25, global step 2600: 'train_loss' was not in top 1\n",
      "Epoch 26, global step 2700: 'train_loss' reached 3.36858 (best 3.36858), saving model to '/mnt/scratch/kashif/ConvTS-Mixer/lightning_logs/version_142/checkpoints/epoch=26-step=2700.ckpt' as top 1\n",
      "Epoch 27, global step 2800: 'train_loss' was not in top 1\n",
      "Epoch 28, global step 2900: 'train_loss' was not in top 1\n",
      "Epoch 29, global step 3000: 'train_loss' was not in top 1\n",
      "Epoch 30, global step 3100: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 3200: 'train_loss' was not in top 1\n",
      "Epoch 32, global step 3300: 'train_loss' reached 3.36519 (best 3.36519), saving model to '/mnt/scratch/kashif/ConvTS-Mixer/lightning_logs/version_142/checkpoints/epoch=32-step=3300.ckpt' as top 1\n",
      "Epoch 33, global step 3400: 'train_loss' was not in top 1\n",
      "Epoch 34, global step 3500: 'train_loss' was not in top 1\n",
      "Epoch 35, global step 3600: 'train_loss' was not in top 1\n",
      "Epoch 36, global step 3700: 'train_loss' reached 3.36508 (best 3.36508), saving model to '/mnt/scratch/kashif/ConvTS-Mixer/lightning_logs/version_142/checkpoints/epoch=36-step=3700.ckpt' as top 1\n",
      "Epoch 37, global step 3800: 'train_loss' was not in top 1\n",
      "Epoch 38, global step 3900: 'train_loss' reached 3.36257 (best 3.36257), saving model to '/mnt/scratch/kashif/ConvTS-Mixer/lightning_logs/version_142/checkpoints/epoch=38-step=3900.ckpt' as top 1\n",
      "Epoch 39, global step 4000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 4100: 'train_loss' reached 3.35411 (best 3.35411), saving model to '/mnt/scratch/kashif/ConvTS-Mixer/lightning_logs/version_142/checkpoints/epoch=40-step=4100.ckpt' as top 1\n",
      "Epoch 41, global step 4200: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 4300: 'train_loss' was not in top 1\n",
      "Epoch 43, global step 4400: 'train_loss' was not in top 1\n",
      "Epoch 44, global step 4500: 'train_loss' reached 3.34982 (best 3.34982), saving model to '/mnt/scratch/kashif/ConvTS-Mixer/lightning_logs/version_142/checkpoints/epoch=44-step=4500.ckpt' as top 1\n",
      "Epoch 45, global step 4600: 'train_loss' was not in top 1\n",
      "Epoch 46, global step 4700: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 4800: 'train_loss' reached 3.33698 (best 3.33698), saving model to '/mnt/scratch/kashif/ConvTS-Mixer/lightning_logs/version_142/checkpoints/epoch=47-step=4800.ckpt' as top 1\n",
      "Epoch 48, global step 4900: 'train_loss' reached 3.33544 (best 3.33544), saving model to '/mnt/scratch/kashif/ConvTS-Mixer/lightning_logs/version_142/checkpoints/epoch=48-step=4900.ckpt' as top 1\n",
      "Epoch 49, global step 5000: 'train_loss' was not in top 1\n",
      "Epoch 50, global step 5100: 'train_loss' reached 3.32844 (best 3.32844), saving model to '/mnt/scratch/kashif/ConvTS-Mixer/lightning_logs/version_142/checkpoints/epoch=50-step=5100.ckpt' as top 1\n",
      "Epoch 51, global step 5200: 'train_loss' was not in top 1\n",
      "Epoch 52, global step 5300: 'train_loss' reached 3.32652 (best 3.32652), saving model to '/mnt/scratch/kashif/ConvTS-Mixer/lightning_logs/version_142/checkpoints/epoch=52-step=5300.ckpt' as top 1\n",
      "Epoch 53, global step 5400: 'train_loss' reached 3.31395 (best 3.31395), saving model to '/mnt/scratch/kashif/ConvTS-Mixer/lightning_logs/version_142/checkpoints/epoch=53-step=5400.ckpt' as top 1\n",
      "Epoch 54, global step 5500: 'train_loss' was not in top 1\n",
      "Epoch 55, global step 5600: 'train_loss' was not in top 1\n",
      "Epoch 56, global step 5700: 'train_loss' was not in top 1\n",
      "Epoch 57, global step 5800: 'train_loss' was not in top 1\n",
      "Epoch 58, global step 5900: 'train_loss' was not in top 1\n",
      "Epoch 59, global step 6000: 'train_loss' was not in top 1\n",
      "Epoch 60, global step 6100: 'train_loss' reached 3.31286 (best 3.31286), saving model to '/mnt/scratch/kashif/ConvTS-Mixer/lightning_logs/version_142/checkpoints/epoch=60-step=6100.ckpt' as top 1\n",
      "Epoch 61, global step 6200: 'train_loss' was not in top 1\n",
      "Epoch 62, global step 6300: 'train_loss' was not in top 1\n",
      "Epoch 63, global step 6400: 'train_loss' reached 3.30633 (best 3.30633), saving model to '/mnt/scratch/kashif/ConvTS-Mixer/lightning_logs/version_142/checkpoints/epoch=63-step=6400.ckpt' as top 1\n",
      "Epoch 64, global step 6500: 'train_loss' was not in top 1\n",
      "Epoch 65, global step 6600: 'train_loss' was not in top 1\n",
      "Epoch 66, global step 6700: 'train_loss' was not in top 1\n",
      "Epoch 67, global step 6800: 'train_loss' reached 3.30425 (best 3.30425), saving model to '/mnt/scratch/kashif/ConvTS-Mixer/lightning_logs/version_142/checkpoints/epoch=67-step=6800.ckpt' as top 1\n",
      "Epoch 68, global step 6900: 'train_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69, global step 7000: 'train_loss' was not in top 1\n",
      "Epoch 70, global step 7100: 'train_loss' reached 3.30263 (best 3.30263), saving model to '/mnt/scratch/kashif/ConvTS-Mixer/lightning_logs/version_142/checkpoints/epoch=70-step=7100.ckpt' as top 1\n",
      "Epoch 71, global step 7200: 'train_loss' was not in top 1\n",
      "Epoch 72, global step 7300: 'train_loss' reached 3.29853 (best 3.29853), saving model to '/mnt/scratch/kashif/ConvTS-Mixer/lightning_logs/version_142/checkpoints/epoch=72-step=7300.ckpt' as top 1\n",
      "Epoch 73, global step 7400: 'train_loss' was not in top 1\n",
      "Epoch 74, global step 7500: 'train_loss' was not in top 1\n",
      "Epoch 75, global step 7600: 'train_loss' reached 3.29573 (best 3.29573), saving model to '/mnt/scratch/kashif/ConvTS-Mixer/lightning_logs/version_142/checkpoints/epoch=75-step=7600.ckpt' as top 1\n",
      "Epoch 76, global step 7700: 'train_loss' reached 3.29283 (best 3.29283), saving model to '/mnt/scratch/kashif/ConvTS-Mixer/lightning_logs/version_142/checkpoints/epoch=76-step=7700.ckpt' as top 1\n",
      "Epoch 77, global step 7800: 'train_loss' was not in top 1\n",
      "Epoch 78, global step 7900: 'train_loss' reached 3.27964 (best 3.27964), saving model to '/mnt/scratch/kashif/ConvTS-Mixer/lightning_logs/version_142/checkpoints/epoch=78-step=7900.ckpt' as top 1\n",
      "Epoch 79, global step 8000: 'train_loss' was not in top 1\n",
      "Epoch 80, global step 8100: 'train_loss' was not in top 1\n",
      "Epoch 81, global step 8200: 'train_loss' was not in top 1\n",
      "Epoch 82, global step 8300: 'train_loss' was not in top 1\n",
      "Epoch 83, global step 8400: 'train_loss' was not in top 1\n",
      "Epoch 84, global step 8500: 'train_loss' was not in top 1\n",
      "Epoch 85, global step 8600: 'train_loss' was not in top 1\n",
      "Epoch 86, global step 8700: 'train_loss' was not in top 1\n",
      "Epoch 87, global step 8800: 'train_loss' was not in top 1\n",
      "Epoch 88, global step 8900: 'train_loss' was not in top 1\n",
      "Epoch 89, global step 9000: 'train_loss' was not in top 1\n",
      "Epoch 90, global step 9100: 'train_loss' reached 3.27557 (best 3.27557), saving model to '/mnt/scratch/kashif/ConvTS-Mixer/lightning_logs/version_142/checkpoints/epoch=90-step=9100.ckpt' as top 1\n",
      "Epoch 91, global step 9200: 'train_loss' was not in top 1\n",
      "Epoch 92, global step 9300: 'train_loss' was not in top 1\n",
      "Epoch 93, global step 9400: 'train_loss' was not in top 1\n",
      "Epoch 94, global step 9500: 'train_loss' was not in top 1\n",
      "Epoch 95, global step 9600: 'train_loss' reached 3.26210 (best 3.26210), saving model to '/mnt/scratch/kashif/ConvTS-Mixer/lightning_logs/version_142/checkpoints/epoch=95-step=9600.ckpt' as top 1\n",
      "Epoch 96, global step 9700: 'train_loss' was not in top 1\n",
      "Epoch 97, global step 9800: 'train_loss' was not in top 1\n",
      "Epoch 98, global step 9900: 'train_loss' was not in top 1\n",
      "Epoch 99, global step 10000: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    }
   ],
   "source": [
    "predictor = estimator.train(\n",
    "    training_data=dataset_train,\n",
    "    cache_data=True,\n",
    "    shuffle_buffer_length=1024,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3426e0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_it, ts_it = make_evaluation_predictions(\n",
    "    dataset=dataset_test, predictor=predictor, num_samples=100\n",
    ")\n",
    "forecasts = list(forecast_it)\n",
    "targets = list(ts_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b96e5127",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MultivariateEvaluator(\n",
    "    quantiles=(np.arange(20) / 20.0)[1:], target_agg_funcs={\"sum\": np.sum}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5946f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 7it [00:00, 72.80it/s]\n",
      "Running evaluation: 7it [00:00, 111.39it/s]\n",
      "Running evaluation: 7it [00:00, 110.80it/s]\n",
      "Running evaluation: 7it [00:00, 110.80it/s]\n",
      "Running evaluation: 7it [00:00, 112.00it/s]\n",
      "Running evaluation: 7it [00:00, 112.25it/s]\n",
      "Running evaluation: 7it [00:00, 112.36it/s]\n",
      "Running evaluation: 7it [00:00, 111.67it/s]\n",
      "Running evaluation: 7it [00:00, 112.26it/s]\n",
      "Running evaluation: 7it [00:00, 112.67it/s]\n",
      "Running evaluation: 7it [00:00, 112.34it/s]\n",
      "Running evaluation: 7it [00:00, 112.46it/s]\n",
      "Running evaluation: 7it [00:00, 112.61it/s]\n",
      "Running evaluation: 7it [00:00, 112.46it/s]\n",
      "Running evaluation: 7it [00:00, 112.19it/s]\n",
      "Running evaluation: 7it [00:00, 111.27it/s]\n",
      "Running evaluation: 7it [00:00, 111.52it/s]\n",
      "Running evaluation: 7it [00:00, 111.46it/s]\n",
      "Running evaluation: 7it [00:00, 112.73it/s]\n",
      "Running evaluation: 7it [00:00, 112.38it/s]\n",
      "Running evaluation: 7it [00:00, 111.58it/s]\n",
      "Running evaluation: 7it [00:00, 112.23it/s]\n",
      "Running evaluation: 7it [00:00, 112.29it/s]\n",
      "Running evaluation: 7it [00:00, 111.79it/s]\n",
      "Running evaluation: 7it [00:00, 112.02it/s]\n",
      "Running evaluation: 7it [00:00, 112.26it/s]\n",
      "Running evaluation: 7it [00:00, 110.05it/s]\n",
      "Running evaluation: 7it [00:00, 108.82it/s]\n",
      "Running evaluation: 7it [00:00, 111.73it/s]\n",
      "Running evaluation: 7it [00:00, 111.64it/s]\n",
      "Running evaluation: 7it [00:00, 110.83it/s]\n",
      "Running evaluation: 7it [00:00, 112.34it/s]\n",
      "Running evaluation: 7it [00:00, 111.82it/s]\n",
      "Running evaluation: 7it [00:00, 111.98it/s]\n",
      "Running evaluation: 7it [00:00, 111.82it/s]\n",
      "Running evaluation: 7it [00:00, 111.98it/s]\n",
      "Running evaluation: 7it [00:00, 111.87it/s]\n",
      "Running evaluation: 7it [00:00, 111.62it/s]\n",
      "Running evaluation: 7it [00:00, 112.09it/s]\n",
      "Running evaluation: 7it [00:00, 112.39it/s]\n",
      "Running evaluation: 7it [00:00, 111.28it/s]\n",
      "Running evaluation: 7it [00:00, 111.67it/s]\n",
      "Running evaluation: 7it [00:00, 111.49it/s]\n",
      "Running evaluation: 7it [00:00, 112.18it/s]\n",
      "Running evaluation: 7it [00:00, 112.21it/s]\n",
      "Running evaluation: 7it [00:00, 111.62it/s]\n",
      "Running evaluation: 7it [00:00, 111.94it/s]\n",
      "Running evaluation: 7it [00:00, 112.64it/s]\n",
      "Running evaluation: 7it [00:00, 112.58it/s]\n",
      "Running evaluation: 7it [00:00, 112.42it/s]\n",
      "Running evaluation: 7it [00:00, 111.71it/s]\n",
      "Running evaluation: 7it [00:00, 112.24it/s]\n",
      "Running evaluation: 7it [00:00, 112.09it/s]\n",
      "Running evaluation: 7it [00:00, 112.12it/s]\n",
      "Running evaluation: 7it [00:00, 112.21it/s]\n",
      "Running evaluation: 7it [00:00, 111.60it/s]\n",
      "Running evaluation: 7it [00:00, 111.86it/s]\n",
      "Running evaluation: 7it [00:00, 112.34it/s]\n",
      "Running evaluation: 7it [00:00, 112.11it/s]\n",
      "Running evaluation: 7it [00:00, 109.07it/s]\n",
      "Running evaluation: 7it [00:00, 109.23it/s]\n",
      "Running evaluation: 7it [00:00, 111.79it/s]\n",
      "Running evaluation: 7it [00:00, 112.39it/s]\n",
      "Running evaluation: 7it [00:00, 112.44it/s]\n",
      "Running evaluation: 7it [00:00, 112.94it/s]\n",
      "Running evaluation: 7it [00:00, 112.34it/s]\n",
      "Running evaluation: 7it [00:00, 112.31it/s]\n",
      "Running evaluation: 7it [00:00, 112.80it/s]\n",
      "Running evaluation: 7it [00:00, 111.94it/s]\n",
      "Running evaluation: 7it [00:00, 112.84it/s]\n",
      "Running evaluation: 7it [00:00, 112.72it/s]\n",
      "Running evaluation: 7it [00:00, 112.64it/s]\n",
      "Running evaluation: 7it [00:00, 112.80it/s]\n",
      "Running evaluation: 7it [00:00, 112.91it/s]\n",
      "Running evaluation: 7it [00:00, 112.99it/s]\n",
      "Running evaluation: 7it [00:00, 112.28it/s]\n",
      "Running evaluation: 7it [00:00, 112.39it/s]\n",
      "Running evaluation: 7it [00:00, 112.81it/s]\n",
      "Running evaluation: 7it [00:00, 112.37it/s]\n",
      "Running evaluation: 7it [00:00, 112.79it/s]\n",
      "Running evaluation: 7it [00:00, 112.38it/s]\n",
      "Running evaluation: 7it [00:00, 112.99it/s]\n",
      "Running evaluation: 7it [00:00, 112.21it/s]\n",
      "Running evaluation: 7it [00:00, 112.56it/s]\n",
      "Running evaluation: 7it [00:00, 112.06it/s]\n",
      "Running evaluation: 7it [00:00, 22.78it/s]\n",
      "Running evaluation: 7it [00:00, 112.32it/s]\n",
      "Running evaluation: 7it [00:00, 112.81it/s]\n",
      "Running evaluation: 7it [00:00, 112.02it/s]\n",
      "Running evaluation: 7it [00:00, 112.21it/s]\n",
      "Running evaluation: 7it [00:00, 112.38it/s]\n",
      "Running evaluation: 7it [00:00, 112.32it/s]\n",
      "Running evaluation: 7it [00:00, 111.77it/s]\n",
      "Running evaluation: 7it [00:00, 112.42it/s]\n",
      "Running evaluation: 7it [00:00, 112.05it/s]\n",
      "Running evaluation: 7it [00:00, 109.66it/s]\n",
      "Running evaluation: 7it [00:00, 106.26it/s]\n",
      "Running evaluation: 7it [00:00, 108.66it/s]\n",
      "Running evaluation: 7it [00:00, 112.14it/s]\n",
      "Running evaluation: 7it [00:00, 112.07it/s]\n",
      "Running evaluation: 7it [00:00, 112.28it/s]\n",
      "Running evaluation: 7it [00:00, 112.08it/s]\n",
      "Running evaluation: 7it [00:00, 111.99it/s]\n",
      "Running evaluation: 7it [00:00, 111.37it/s]\n",
      "Running evaluation: 7it [00:00, 111.49it/s]\n",
      "Running evaluation: 7it [00:00, 111.67it/s]\n",
      "Running evaluation: 7it [00:00, 111.73it/s]\n",
      "Running evaluation: 7it [00:00, 112.31it/s]\n",
      "Running evaluation: 7it [00:00, 112.02it/s]\n",
      "Running evaluation: 7it [00:00, 112.49it/s]\n",
      "Running evaluation: 7it [00:00, 112.34it/s]\n",
      "Running evaluation: 7it [00:00, 112.89it/s]\n",
      "Running evaluation: 7it [00:00, 112.61it/s]\n",
      "Running evaluation: 7it [00:00, 111.39it/s]\n",
      "Running evaluation: 7it [00:00, 111.56it/s]\n",
      "Running evaluation: 7it [00:00, 110.54it/s]\n",
      "Running evaluation: 7it [00:00, 112.12it/s]\n",
      "Running evaluation: 7it [00:00, 112.11it/s]\n",
      "Running evaluation: 7it [00:00, 112.68it/s]\n",
      "Running evaluation: 7it [00:00, 111.77it/s]\n",
      "Running evaluation: 7it [00:00, 112.18it/s]\n",
      "Running evaluation: 7it [00:00, 112.40it/s]\n",
      "Running evaluation: 7it [00:00, 112.34it/s]\n",
      "Running evaluation: 7it [00:00, 111.63it/s]\n",
      "Running evaluation: 7it [00:00, 112.28it/s]\n",
      "Running evaluation: 7it [00:00, 112.60it/s]\n",
      "Running evaluation: 7it [00:00, 111.96it/s]\n",
      "Running evaluation: 7it [00:00, 112.57it/s]\n",
      "Running evaluation: 7it [00:00, 112.32it/s]\n",
      "Running evaluation: 7it [00:00, 112.36it/s]\n",
      "Running evaluation: 7it [00:00, 112.35it/s]\n",
      "Running evaluation: 7it [00:00, 112.42it/s]\n",
      "Running evaluation: 7it [00:00, 111.95it/s]\n",
      "Running evaluation: 7it [00:00, 112.26it/s]\n",
      "Running evaluation: 7it [00:00, 111.66it/s]\n",
      "Running evaluation: 7it [00:00, 110.19it/s]\n",
      "Running evaluation: 7it [00:00, 108.93it/s]\n",
      "Running evaluation: 7it [00:00, 87.49it/s]\n"
     ]
    }
   ],
   "source": [
    "agg_metric, _ = evaluator(targets, forecasts, num_series=len(dataset_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37a909b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRPS-Sum: 0.32429501431459606\n",
      "CRPS: 0.3625486813719906\n",
      "QL50: 0.4988281185856732\n",
      "QL90: 0.20497564379619174\n",
      "MSIS: 7.8547312171213095\n",
      "NRMSE: 0.9782419894884901\n",
      "sMAPE: 1.3554419422050215\n",
      "MASE: 1.1668081421889942\n"
     ]
    }
   ],
   "source": [
    "print(\"CRPS-Sum: {}\".format(agg_metric[\"m_sum_mean_wQuantileLoss\"]))\n",
    "print(\"CRPS: {}\".format(agg_metric[\"mean_wQuantileLoss\"]))\n",
    "print(\"QL50: {}\".format(agg_metric[\"wQuantileLoss[0.5]\"]))\n",
    "print(\"QL90: {}\".format(agg_metric[\"wQuantileLoss[0.9]\"]))\n",
    "print(\"MSIS: {}\".format(agg_metric[\"MSIS\"]))\n",
    "print(\"NRMSE: {}\".format(agg_metric[\"NRMSE\"]))\n",
    "print(\"sMAPE: {}\".format(agg_metric[\"sMAPE\"]))\n",
    "print(\"MASE: {}\".format(agg_metric[\"MASE\"]))\n",
    "\n",
    "# print(\"ND: {}\".format(agg_metric[\"ND\"]))\n",
    "# print(\"NRMSE: {}\".format(agg_metric[\"NRMSE\"]))\n",
    "# print(\"MSE: {}\".format(agg_metric[\"MSE\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9de7d0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRPS: 0.3475042523854184\n",
      "ND: 0.49421386986725574\n",
      "NRMSE: 0.9454882241836582\n",
      "MSE: 847.98864290372\n",
      "CRPS-SUM: 0.29327103321837134\n"
     ]
    }
   ],
   "source": [
    "print(\"CRPS: {}\".format(agg_metric[\"mean_wQuantileLoss\"]))\n",
    "print(\"ND: {}\".format(agg_metric[\"ND\"]))\n",
    "print(\"NRMSE: {}\".format(agg_metric[\"NRMSE\"]))\n",
    "print(\"MSE: {}\".format(agg_metric[\"MSE\"]))\n",
    "\n",
    "print(\"CRPS-SUM: {}\".format(agg_metric[\"m_sum_mean_wQuantileLoss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfd2ad06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot(\n",
    "    target,\n",
    "    forecast,\n",
    "    prediction_length,\n",
    "    prediction_intervals=(50.0, 90.0),\n",
    "    color=\"g\",\n",
    "    fname=None,\n",
    "):\n",
    "    label_prefix = \"\"\n",
    "    rows = 4\n",
    "    cols = 4\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(24, 24))\n",
    "    axx = axs.ravel()\n",
    "    seq_len, target_dim = target.shape\n",
    "\n",
    "    ps = [50.0] + [\n",
    "        50.0 + f * c / 2.0 for c in prediction_intervals for f in [-1.0, +1.0]\n",
    "    ]\n",
    "\n",
    "    percentiles_sorted = sorted(set(ps))\n",
    "\n",
    "    def alpha_for_percentile(p):\n",
    "        return (p / 100.0) ** 0.3\n",
    "\n",
    "    for dim in range(0, min(rows * cols, target_dim)):\n",
    "        ax = axx[dim]\n",
    "\n",
    "        target[-2 * prediction_length :][dim].plot(ax=ax)\n",
    "\n",
    "        ps_data = [forecast.quantile(p / 100.0)[:, dim] for p in percentiles_sorted]\n",
    "        i_p50 = len(percentiles_sorted) // 2\n",
    "\n",
    "        p50_data = ps_data[i_p50]\n",
    "        p50_series = pd.Series(data=p50_data, index=forecast.index)\n",
    "        p50_series.plot(color=color, ls=\"-\", label=f\"{label_prefix}median\", ax=ax)\n",
    "\n",
    "        for i in range(len(percentiles_sorted) // 2):\n",
    "            ptile = percentiles_sorted[i]\n",
    "            alpha = alpha_for_percentile(ptile)\n",
    "            ax.fill_between(\n",
    "                forecast.index,\n",
    "                ps_data[i],\n",
    "                ps_data[-i - 1],\n",
    "                facecolor=color,\n",
    "                alpha=alpha,\n",
    "                interpolate=True,\n",
    "            )\n",
    "            # Hack to create labels for the error intervals.\n",
    "            # Doesn't actually plot anything, because we only pass a single data point\n",
    "            pd.Series(data=p50_data[:1], index=forecast.index[:1]).plot(\n",
    "                color=color,\n",
    "                alpha=alpha,\n",
    "                linewidth=10,\n",
    "                label=f\"{label_prefix}{100 - ptile * 2}%\",\n",
    "                ax=ax,\n",
    "            )\n",
    "\n",
    "    legend = [\"observations\", \"median prediction\"] + [\n",
    "        f\"{k}% prediction interval\" for k in prediction_intervals\n",
    "    ][::-1]\n",
    "    axx[0].legend(legend, loc=\"upper left\")\n",
    "\n",
    "    if fname is not None:\n",
    "        plt.savefig(fname, bbox_inches=\"tight\", pad_inches=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3858db8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'targets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m plot(\n\u001b[0;32m----> 2\u001b[0m     target\u001b[38;5;241m=\u001b[39m\u001b[43mtargets\u001b[49m[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m      3\u001b[0m     forecast\u001b[38;5;241m=\u001b[39mforecasts[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m      4\u001b[0m     prediction_length\u001b[38;5;241m=\u001b[39mdataset\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mprediction_length,\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'targets' is not defined"
     ]
    }
   ],
   "source": [
    "plot(\n",
    "    target=targets[0],\n",
    "    forecast=forecasts[0],\n",
    "    prediction_length=dataset.metadata.prediction_length,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4771755",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
